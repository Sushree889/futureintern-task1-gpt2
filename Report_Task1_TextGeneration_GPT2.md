# Task 1 â€“ Text Generation Using GPT-2 (FutureIntern Internship)

This repository contains the implementation of **text generation using the GPT-2 model** as part of **Task 1** for the FutureIntern internship.

## What I Did

- Used **Google Colab** to access a Python-based notebook.
- Loaded the **pre-trained GPT-2 model** using the Hugging Face `transformers` library.
- Entered a custom text prompt to generate AI-based completions.
- Ran the model to get multiple text outputs and analyzed their creativity.
- Saved the best output for future reference or content generation.

## Platform Used

- **Google Colab**  
  [https://colab.research.google.com](https://colab.research.google.com)

## Libraries/Tools Used

- `transformers` by Hugging Face
- `torch`
- Pre-trained **GPT-2** language model

## Sample Prompt Used

> *"In the future, artificial intelligence will completely change the way humans interact with..."*

## Output Example

> "In the future, artificial intelligence will completely change the way humans interact with technology. From voice-based systems to full-fledged humanoid assistants, AI will be deeply integrated into our daily lives..."

## Task Credit

This task was completed as part of the **FutureIntern Online Internship Program** under the module:  
**Text Generation using Pre-trained AI Tools (GPT-2).**
